<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>My Website</title>
    <link>/</link>
    <description>Recent content on My Website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Fri, 11 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>First post, last assignment</title>
      <link>/post/2020/12/11/first-post-last-assignment/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/12/11/first-post-last-assignment/</guid>
      <description>Beaver body temperature I scrolled through the list of datasets in R looking for a fun one to use for this post, settled on this dataset because I saw a video of a beaver earlier today and he was very cute. The output gives us the mean body temperature (in degrees Celsius) over the period of a day for the beaver studied in this data.
library(boot) head(beaver1) ## day time temp activ ## 1 346 840 36.</description>
    </item>
    
    <item>
      <title>Test Post</title>
      <link>/post/2020/12/11/test-post/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/12/11/test-post/</guid>
      <description> Heading of my post Content of my post
Subheading More content
  </description>
    </item>
    
    <item>
      <title>Project 1: Formula One Exploratory Data Analysis</title>
      <link>/project/project1/</link>
      <pubDate>Sun, 18 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/project/project1/</guid>
      <description>In this project I will be using two datasets containing information from Formula One (F1) Racing dating from 1950-2018. The first dataset is called &amp;quot;results&amp;quot; and contains the results of over 1000 race with over 23,000 data points. This data set has variables including every driver, constructor, race, fastestlaptime, points, finishing position, etc.The second dataset is called &amp;quot;qualifying1&amp;quot; and contains data from the qualifying sessions of all of the same races as in the previou dataset.</description>
    </item>
    
    <item>
      <title>Project 2: NFL Betting Modeling, Testing, and Predicting</title>
      <link>/project/project2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/project/project2/</guid>
      <description>Data Introduction In this project I will be using an NFL betting dataset I found from kaggle. From that dataset I created this one which includes every game from the 2016 season. A little betting terminology knowledge is necessary for understanding this data. The game &amp;quot;spread&amp;quot; is how much a team is expected to win by, the &amp;quot;over/under line&amp;quot; is how many total points are expected to be scored by both teams combined in a game.</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects/</guid>
      <description> Check out some of my coding projects below:
 Wrangling &amp;amp; Exploratory Data Analysis
 Modeling, Inference, Prediction
  -- </description>
    </item>
    
    <item>
      <title>Resume</title>
      <link>/resume/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/resume/</guid>
      <description>    </description>
    </item>
    
  </channel>
</rss>
